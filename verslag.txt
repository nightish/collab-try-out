

       Inhoudsopgave
-		    Inleiding
Hoofdstuk 1	Opleiding
Hoofdstuk 2	Functies en beperkingen
Hoofdstuk 3	Receptie
Hoofdstuk 4	Gevolgen op de samenleving van Chat GPT
Hoofdstuk 5	Concurrentie


Inleiding

ChatGPT is een chatbot voor kunstmatige intelligentie ontwikkeld door OpenAI en gelanceerd in november 2022. Het is gebouwd bovenop OpenAI's GPT-3.5 en GPT-4 families van grote taalmodellen (LLMs) en is verfijnd (een benadering van transfer learning) met behulp van zowel supervised als reinforcement learning technieken.

ChatGPT werd gelanceerd als een prototype op 30 november 2022 en kreeg al snel aandacht voor zijn gedetailleerde antwoorden en gearticuleerde antwoorden op vele kennisdomeinen. De ongelijke feitelijke nauwkeurigheid ervan is echter als een belangrijk nadeel aangemerkt. Na de release van ChatGPT werd de waardering van OpenAI geschat op US$ 29 miljard in 2023.

ChatGPT werd oorspronkelijk uitgebracht in november 2022 op basis van GPT-3.5 en GPT-4, het nieuwste OpenAI-model, werd uitgebracht op 14 maart 2023 en is beschikbaar voor ChatGPT Plus-gebruikers.


Opleiding

ChatGPT is een lid van de generatieve voorgetrainde transformator (GPT) familie van taalmodellen. Het werd verfijnd (een benadering van transfer learning) ten  opzichte van een verbeterde versie van OpenAI's GPT-3 bekend als "GPT 3.5". Het fine-tuningproces maakte gebruik van zowel supervised learning als reinforcement learning in een proces dat reinforcement learning from human feedback (RLHF)   wordt genoemd. Beide benaderingen gebruikten menselijke trainers om de prestaties van het model te verbeteren. 

In het geval van supervised learning werd het model voorzien van gesprekken waarin de trainers aan beide kanten speelden: de gebruiker en de AI-assistent. In de reinforcement learning-stap rangschikten menselijke trainers eerst reacties die het model in een eerder gesprek had gemaakt.

Deze ranglijsten werden gebruikt om 'beloningsmodellen' te maken waarop het     model verder werd afgestemd met behulp van verschillende iteraties van Proximale Beleidsoptimalisatie (PPO) Proximale beleidsoptimalisatie-algoritmen bieden een kosteneffectief voordeel voor algoritmen voor het vertrouwen in regiobeleidsoptimalisatie; ze ontkrachten veel van de rekensomrijke bewerkingen met snellere prestaties. De modellen werden getraind in samenwerking met Microsoft op hun Azure supercomputing infrastructuur, met behulp van Nvidia GPU's, "supercomputer ontwikkeld voor OpenAI is een enkel systeem met meer dan 285.000 CPU-kernen, 10.000 GPU's en 400 gigabit per seconde netwerkconnectiviteit voor elke GPU-server".

Daarnaast blijft OpenAI gegevens van ChatGPT-gebruikers verzamelen die kunnen worden gebruikt om ChatGPT verder te trainen en te verfijnen. Gebruikers kunnen reacties die ze ontvangen van ChatGPT upvoten of downvoten en een tekstveld invullen met aanvullende feedback.


Features:
Het hoofddoel van ChatGPT is mensenelijke gesprekken nabootsen, maar het is tot veel meer instaat.
Het kan muziek schrijven, helpen met programmeren, helpen teksten schrijven, verhalen verzinnen, en meer. ChatGPT onthoudt bovendien wat men hem in het verleden heeft gevraagt, waardoor hij continue zichzelf kan uitbreiden.

Het is echter niet zonder limieten. Soms schrijft het dingen die waar klinken maar volledig uit de lucht zijn gegrepen of foutief zijn.
Het heeft zeer weining kennis over gebeurtenissen na September 2021 en mag in principe geen politiek getinde antwoorden geven, alhoewel deze beperkin omzeild kan worden


Gevolgen van Chatgpt op het gebied van cyberbeveiliging en in de academische wereld

Check Point Research en anderen merkten op dat ChatGPT in staat was om phishing - e - mails en malware te schrijven , vooral in combinatie met OpenAI Codex .  Sam Altman , CEO van OpenAI , schreef dat voortschrijdende software "(bijvoorbeeld) een enorm cyberbeveiligingsrisico zou kunnen vormen" en bleef ook voorspellen "dat we in het volgende decennium tot echte AGI ( kunstmatige algemene intelligentie ) zouden kunnen komen, dus we moeten nemen het risico daarvan uiterst serieus". Altman voerde aan dat, hoewel ChatGPT "duidelijk niet in de buurt komt van AGI", men "het exponentiÃ«le moet vertrouwen . Plat achteruit kijkend, verticaal vooruitkijkend ". 
ChatGPT kan inleidende en abstracte delen van wetenschappelijke artikelen schrijven, wat ethische vragen oproept. Verschillende artikelen hebben ChatGPT al als co-auteur vermeld. 

In het tijdschrift The Atlantic merkte Stephen Marche op dat het effect ervan op de academische wereld en vooral op sollicitatie-essays nog niet duidelijk is. De Californische middelbare schoolleraar en auteur Daniel Herman schreef dat ChatGPT "het einde van het Engels op de middelbare school" zou inluiden. In het tijdschrift Nature wees Chris Stokel-Walker erop dat leraren zich zorgen moeten maken over studenten die ChatGPT gebruiken om hun schrijven uit te besteden, maar dat onderwijsaanbieders zich zullen aanpassen om kritisch denken of redeneren te verbeteren. Emma Bowman met NPRschreef over het gevaar van plagiaat door studenten via een AI-tool die bevooroordeelde of onzinnige tekst met een gezaghebbende toon kan produceren: "Er zijn nog steeds veel gevallen waarin je het een vraag stelt en het je een zeer indrukwekkend klinkend antwoord geeft dat gewoon dood is fout." 

Joanna Stern van The Wall Street Journal beschreef bedrog in Amerikaans high school English met de tool door een gegenereerd essay in te dienen. Professor Darren Hick van Furman University beschreef het opmerken van de "stijl" van ChatGPT in een paper die door een student was ingediend. Een online GPT-detector beweerde dat de krant voor 99,9 procent waarschijnlijk door de computer was gegenereerd, maar Hick had geen hard bewijs. De student in kwestie bekende echter dat hij GPT had gebruikt toen hij werd geconfronteerd, en zakte als gevolg daarvan voor de cursus. Hick stelde een beleid voor om een ad-hoc individueel mondeling examen over het paper-onderwerp te geven als een student sterk wordt verdacht van het indienen van een door AI gegenereerd paper. Edward Tian, een laatstejaars student aanPrinceton University heeft een programma gemaakt met de naam "GPTZero", dat bepaalt hoeveel van een tekst AI-gegenereerd is, en leent zich om te worden gebruikt om te detecteren of een essay door mensen is geschreven om academisch plagiaat te bestrijden .  

Het New York City Department of Education blokkeerde naar verluidt de toegang tot ChatGPT in december 2022, en kondigde officieel een verbod aan rond 4 januari 2023.  
In een geblindeerde test werd geoordeeld dat ChatGPT geslaagd was voor examens op graduaatniveau aan de Universiteit van Minnesota op het niveau van een C+  student en aan de Wharton School van de Universiteit van Pennsylvania met een B  tot  B-graad. 
Wetenschappelijke tijdschriften hebben verschillende reacties op ChatGPT: sommige "eisen dat auteurs het gebruik van tekstgenererende tools bekendmaken en verbieden een groot taalmodel (LLM) zoals ChatGPT als co-auteur op te nemen", bijvoorbeeld Nature en JAMA Network . De wetenschap heeft het gebruik van door LLM gegenereerde tekst in al haar tijdschriften "volledig verboden".  Wat de gezondheidszorg betreft, worden mogelijke toepassingen en problemen nauwkeurig onderzocht door beroepsverenigingen en beoefenaars. 



